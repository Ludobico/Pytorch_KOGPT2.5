{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.37.2-py3-none-any.whl (84.2 MB)\n",
      "     -------------------------------------- 84.2/84.2 MB 108.0 kB/s eta 0:00:00\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.37.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\aqs45\\OneDrive\\바탕 화면\\repo\\Transformers\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\aqs45\\OneDrive\\바탕 화면\\repo\\Transformers\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n",
      "  WARNING: Did not find branch or tag 'c3dc391', assuming revision or ref.\n",
      "WARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\aqs45\\OneDrive\\바탕 화면\\repo\\Transformers\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\aqs45\\OneDrive\\바탕 화면\\repo\\Transformers\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes\n",
    "!pip install -q datasets loralib sentencepiece\n",
    "!pip install -q git+https://github.com/zphang/transformers@c3dc391\n",
    "!pip install -q git+https://github.com/huggingface/peft.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
      "CUDA SETUP: WARNING! libcuda.so not found! Do you have a CUDA driver installed? If you are on a cluster, make sure you are on a CUDA machine!\n",
      "CUDA SETUP: Loading binary c:\\Users\\aqs45\\OneDrive\\바탕 화면\\repo\\Transformers\\venv\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cpu.so...\n",
      "argument of type 'WindowsPath' is not iterable\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
      "CUDA SETUP: WARNING! libcuda.so not found! Do you have a CUDA driver installed? If you are on a cluster, make sure you are on a CUDA machine!\n",
      "CUDA SETUP: Loading binary c:\\Users\\aqs45\\OneDrive\\바탕 화면\\repo\\Transformers\\venv\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cpu.so...\n",
      "argument of type 'WindowsPath' is not iterable\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
      "CUDA SETUP: WARNING! libcuda.so not found! Do you have a CUDA driver installed? If you are on a cluster, make sure you are on a CUDA machine!\n",
      "CUDA SETUP: Loading binary c:\\Users\\aqs45\\OneDrive\\바탕 화면\\repo\\Transformers\\venv\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cpu.so...\n",
      "argument of type 'WindowsPath' is not iterable\n",
      "CUDA SETUP: Problem: The main issue seems to be that the main CUDA library was not detected.\n",
      "CUDA SETUP: Solution 1): Your paths are probably not up-to-date. You can update them via: sudo ldconfig.\n",
      "CUDA SETUP: Solution 2): If you do not have sudo rights, you can do the following:\n",
      "CUDA SETUP: Solution 2a): Find the cuda library via: find / -name libcuda.so 2>/dev/null\n",
      "CUDA SETUP: Solution 2b): Once the library is found add it to the LD_LIBRARY_PATH: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:FOUND_PATH_FROM_2a\n",
      "CUDA SETUP: Solution 2c): For a permanent solution add the export from 2b into your .bashrc file, located at ~/.bashrc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aqs45\\OneDrive\\바탕 화면\\repo\\Transformers\\venv\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {WindowsPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "  warn(msg)\n",
      "c:\\Users\\aqs45\\OneDrive\\바탕 화면\\repo\\Transformers\\venv\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {WindowsPath('module'), WindowsPath('/matplotlib_inline.backend_inline')}\n",
      "  warn(msg)\n",
      "c:\\Users\\aqs45\\OneDrive\\바탕 화면\\repo\\Transformers\\venv\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {WindowsPath('/usr/local/cuda/lib64')}\n",
      "  warn(msg)\n",
      "c:\\Users\\aqs45\\OneDrive\\바탕 화면\\repo\\Transformers\\venv\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:136: UserWarning: WARNING: No libcudart.so found! Install CUDA or the cudatoolkit package (anaconda)!\n",
      "  warn(msg)\n",
      "c:\\Users\\aqs45\\OneDrive\\바탕 화면\\repo\\Transformers\\venv\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:136: UserWarning: WARNING: No GPU detected! Check your CUDA paths. Proceeding to load CPU-only library...\n",
      "  warn(msg)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\n        CUDA Setup failed despite GPU being available. Inspect the CUDA SETUP outputs above to fix your environment!\n        If you cannot find any issues and suspect a bug, please open an issue with detals about your environment:\n        https://github.com/TimDettmers/bitsandbytes/issues",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpeft\u001b[39;00m \u001b[39mimport\u001b[39;00m PeftModel\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtransformers\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m LLaMATokenizer, LLaMAForCausalLM, GenerationConfig\n",
      "File \u001b[1;32mc:\\Users\\aqs45\\OneDrive\\바탕 화면\\repo\\Transformers\\venv\\lib\\site-packages\\peft\\__init__.py:22\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# flake8: noqa\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# There's no way to ignore \"F401 '...' imported but unused\" warnings in this\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# module, but to preserve other warnings. So, don't check this module at all.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.3.0.dev0\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmapping\u001b[39;00m \u001b[39mimport\u001b[39;00m MODEL_TYPE_TO_PEFT_MODEL_MAPPING, PEFT_TYPE_TO_CONFIG_MAPPING, get_peft_config, get_peft_model\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpeft_model\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     24\u001b[0m     PeftModel,\n\u001b[0;32m     25\u001b[0m     PeftModelForCausalLM,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m     PeftModelForTokenClassification,\n\u001b[0;32m     29\u001b[0m )\n\u001b[0;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtuners\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     31\u001b[0m     LoraConfig,\n\u001b[0;32m     32\u001b[0m     LoraModel,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m     PromptTuningInit,\n\u001b[0;32m     43\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\aqs45\\OneDrive\\바탕 화면\\repo\\Transformers\\venv\\lib\\site-packages\\peft\\mapping.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# coding=utf-8\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# Copyright 2023-present the HuggingFace Inc. team.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpeft_model\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     17\u001b[0m     PeftModel,\n\u001b[0;32m     18\u001b[0m     PeftModelForCausalLM,\n\u001b[0;32m     19\u001b[0m     PeftModelForSeq2SeqLM,\n\u001b[0;32m     20\u001b[0m     PeftModelForSequenceClassification,\n\u001b[0;32m     21\u001b[0m     PeftModelForTokenClassification,\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtuners\u001b[39;00m \u001b[39mimport\u001b[39;00m AdaLoraConfig, LoraConfig, PrefixTuningConfig, PromptEncoderConfig, PromptTuningConfig\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m PromptLearningConfig\n",
      "File \u001b[1;32mc:\\Users\\aqs45\\OneDrive\\바탕 화면\\repo\\Transformers\\venv\\lib\\site-packages\\peft\\peft_model.py:31\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodeling_outputs\u001b[39;00m \u001b[39mimport\u001b[39;00m SequenceClassifierOutput, TokenClassifierOutput\n\u001b[0;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m PushToHubMixin\n\u001b[1;32m---> 31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtuners\u001b[39;00m \u001b[39mimport\u001b[39;00m AdaLoraModel, LoraModel, PrefixEncoder, PromptEmbedding, PromptEncoder\n\u001b[0;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     33\u001b[0m     TRANSFORMERS_MODELS_TO_PREFIX_TUNING_POSTPROCESS_MAPPING,\n\u001b[0;32m     34\u001b[0m     WEIGHTS_NAME,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m     shift_tokens_right,\n\u001b[0;32m     44\u001b[0m )\n\u001b[0;32m     47\u001b[0m PEFT_TYPE_TO_MODEL_MAPPING \u001b[39m=\u001b[39m {\n\u001b[0;32m     48\u001b[0m     PeftType\u001b[39m.\u001b[39mLORA: LoraModel,\n\u001b[0;32m     49\u001b[0m     PeftType\u001b[39m.\u001b[39mPROMPT_TUNING: PromptEmbedding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m     PeftType\u001b[39m.\u001b[39mADALORA: AdaLoraModel,\n\u001b[0;32m     53\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\aqs45\\OneDrive\\바탕 화면\\repo\\Transformers\\venv\\lib\\site-packages\\peft\\tuners\\__init__.py:20\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# flake8: noqa\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# There's no way to ignore \"F401 '...' imported but unused\" warnings in this\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# module, but to preserve other warnings. So, don't check this module at all\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlora\u001b[39;00m \u001b[39mimport\u001b[39;00m LoraConfig, LoraModel\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39madalora\u001b[39;00m \u001b[39mimport\u001b[39;00m AdaLoraConfig, AdaLoraModel\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mp_tuning\u001b[39;00m \u001b[39mimport\u001b[39;00m PromptEncoder, PromptEncoderConfig, PromptEncoderReparameterizationType\n",
      "File \u001b[1;32mc:\\Users\\aqs45\\OneDrive\\바탕 화면\\repo\\Transformers\\venv\\lib\\site-packages\\peft\\tuners\\lora.py:39\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     29\u001b[0m     TRANSFORMERS_MODELS_TO_LORA_TARGET_MODULES_MAPPING,\n\u001b[0;32m     30\u001b[0m     PeftConfig,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     transpose,\n\u001b[0;32m     35\u001b[0m )\n\u001b[0;32m     38\u001b[0m \u001b[39mif\u001b[39;00m is_bnb_available():\n\u001b[1;32m---> 39\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mbnb\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[39m@dataclass\u001b[39m\n\u001b[0;32m     43\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mLoraConfig\u001b[39;00m(PeftConfig):\n\u001b[0;32m     44\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[39m    This is the configuration class to store the configuration of a [`LoraModel`].\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39m            and saved in the final checkpoint.\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aqs45\\OneDrive\\바탕 화면\\repo\\Transformers\\venv\\lib\\site-packages\\bitsandbytes\\__init__.py:7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m cuda_setup, utils\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mautograd\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_functions\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     MatmulLtState,\n\u001b[0;32m      9\u001b[0m     bmm_cublas,\n\u001b[0;32m     10\u001b[0m     matmul,\n\u001b[0;32m     11\u001b[0m     matmul_cublas,\n\u001b[0;32m     12\u001b[0m     mm_cublas,\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcextension\u001b[39;00m \u001b[39mimport\u001b[39;00m COMPILED_WITH_CUDA\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mimport\u001b[39;00m modules\n",
      "File \u001b[1;32mc:\\Users\\aqs45\\OneDrive\\바탕 화면\\repo\\Transformers\\venv\\lib\\site-packages\\bitsandbytes\\autograd\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_functions\u001b[39;00m \u001b[39mimport\u001b[39;00m undo_layout, get_inverse_transform_indices\n",
      "File \u001b[1;32mc:\\Users\\aqs45\\OneDrive\\바탕 화면\\repo\\Transformers\\venv\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:9\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Tuple, Optional\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m# math.prod not compatible with python < 3.8\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprod\u001b[39m(iterable):\n",
      "File \u001b[1;32mc:\\Users\\aqs45\\OneDrive\\바탕 화면\\repo\\Transformers\\venv\\lib\\site-packages\\bitsandbytes\\functional.py:17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Tuple\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m Tensor\n\u001b[1;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcextension\u001b[39;00m \u001b[39mimport\u001b[39;00m COMPILED_WITH_CUDA, lib\n\u001b[0;32m     20\u001b[0m \u001b[39m# math.prod not compatible with python < 3.8\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprod\u001b[39m(iterable):\n",
      "File \u001b[1;32mc:\\Users\\aqs45\\OneDrive\\바탕 화면\\repo\\Transformers\\venv\\lib\\site-packages\\bitsandbytes\\cextension.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m     CUDASetup\u001b[39m.\u001b[39mget_instance()\u001b[39m.\u001b[39mgenerate_instructions()\n\u001b[0;32m     21\u001b[0m     CUDASetup\u001b[39m.\u001b[39mget_instance()\u001b[39m.\u001b[39mprint_log_stack()\n\u001b[1;32m---> 22\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'''\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[39m    CUDA Setup failed despite GPU being available. Inspect the CUDA SETUP outputs above to fix your environment!\u001b[39m\n\u001b[0;32m     24\u001b[0m \u001b[39m    If you cannot find any issues and suspect a bug, please open an issue with detals about your environment:\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[39m    https://github.com/TimDettmers/bitsandbytes/issues\u001b[39m\u001b[39m'''\u001b[39m)\n\u001b[0;32m     26\u001b[0m lib\u001b[39m.\u001b[39mcadam32bit_g32\n\u001b[0;32m     27\u001b[0m lib\u001b[39m.\u001b[39mget_context\u001b[39m.\u001b[39mrestype \u001b[39m=\u001b[39m ct\u001b[39m.\u001b[39mc_void_p\n",
      "\u001b[1;31mRuntimeError\u001b[0m: \n        CUDA Setup failed despite GPU being available. Inspect the CUDA SETUP outputs above to fix your environment!\n        If you cannot find any issues and suspect a bug, please open an issue with detals about your environment:\n        https://github.com/TimDettmers/bitsandbytes/issues"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import PeftModel\n",
    "import transformers\n",
    "\n",
    "from transformers import LLaMATokenizer, LLaMAForCausalLM, GenerationConfig\n",
    "\n",
    "tokenizer = LLaMATokenizer.from_pretrained(\"decapoda-research/llama-13b-hf\")\n",
    "\n",
    "BASE_MODEL = \"decapoda-research/llama-13b-hf\"\n",
    "LORA_WEIGHTS = \"C:/Users/aqs45/OneDrive/바탕 화면/alpaca_checkpoint/checkpoint-2800\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
